---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a Research Scientist at Singapore Management University (SMU), working under the guidance of [Prof Chong-Wah Ngo](https://scholar.google.com/citations?user=HM39HrUAAAAJ&hl=en). My research focuses on **multicultural, multilingual food imageâ€“recipe retrieval**, with an emphasis on mitigating biases arising from food images.

I obtained my PhD from the School of Computing and Information Systems at Singapore Management University (SMU), Singapore. My doctoral research focused on food computing, particularly **fine-grained food recognition** and **causality-driven cross-modal, cross-lingual food imageâ€“recipe retrieval**, under the supervision of [Prof Chong-Wah Ngo](https://scholar.google.com/citations?user=HM39HrUAAAAJ&hl=en). I completed my Masterâ€™s degree at Louisiana State University (LSU) under the guidance of [Prof. Mingxuan Sun](http://csc.lsu.edu/~msun/), where I specialized in image generative models.

Recent News
======
* 07/2025: A paper is accepted to MM 2025!
* 03/2025: Started to work as a Research Scientist at SMU.

<span style="color:blue"> -------------------------------------------------------------------------------------------------- </span>

Publications
======
# Research during Post-Doctoral Work

<img src="https://seeingculture-benchmark.github.io/static/images/teaser.png" alt="Seeing Culture Benchmark" width="700"/>

**Seeing Culture: A Benchmark for Visual Reasoning and Grounding** \\
**Burak Satar\***, Zhixin Ma\*, Patrick Amadeus Irawan, Wilfried Ariel Mulyawan, Jing Jiang, Ee-Peng Lim, Chong-Wah Ngo \\
EMNLP 2025 Main Conference \\
[[Project Website](https://seeingculture-benchmark.github.io/)] [[Paper](https://aclanthology.org/2025.emnlp-main.1131)] [[arXiv](https://arxiv.org/abs/2509.16517)] [[Code](https://github.com/buraksatar/seeingculture)] [[ðŸ¤— Dataset](https://huggingface.co/datasets/Multimedia-SMU/seeingculture-benchmark)]

**Retrieval Augmented Reasoning Segmentation in Cultural Context** \\
Zhixin Ma\*, **Burak Satar\***, Patrick Amadeus Irawan, Wilfried Ariel Mulyawan, Phuong Anh Nguyen, Chong-Wah Ngo \\
Under peer review \\
[arXiv] (link to be updated)

# Research during Doctoral Study
## PhD Research Topic 3: Multimodal and Generative Video/Moment Retrieval

**Video Corpus Moment Retrieval in Long Ego-centric Videos with LLM and Audio Fusion** \\
**Burak Satar**, Joo Hwee Lim, Hanwang Zhang, M Furkan Ilaslan, Hongyuan Zhu, Michael Wray \\
(Under development)

**VG-TVP: Multimodal Procedural Planning via Visually Grounded Text-Video Prompting** \\
M Furkan Ilaslan, Ali Koksal, Kevin Qinghong Lin, **Burak Satar**, Mike Zheng Shou, Qianli Xu \\
AAAI 2025 Full Paper \\
[[arXiv](https://arxiv.org/abs/2412.11621)] [[Dataset Link](https://drive.google.com/drive/folders/1-Lka5F-Dh-Fz6CwHDJYjUqieXlt2GCR6)] [[Github](https://github.com/mfurkanilaslan/VG-TVP?tab=readme-ov-file)]

## PhD Research Topic 2: Debiased Text-to-Video Retrieval

<img src="https://buraksatar.github.io/images/scm_camready.png" alt="Structural Causal Model" width="400"/> \\
**Towards Debiasing Frame Length Bias in Text-Video Retrieval via Causal Intervention** \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
BMVC 2023 Full Paper, (Poster presentation) \\
[[arXiv](https://arxiv.org/abs/2309.09311)] [[YouTube Ppt](https://youtu.be/aMhNvTCkT8Y)] [[Poster](https://drive.google.com/file/d/10aXgkCl4PowFelEOyxJp4X90cTtub6Pt/view?usp=sharing)] [[Project Page](https://buraksatar.github.io/FrameLengthBias/)]

<img src="https://buraksatar.github.io/images/cvpr'23_workshop.png" alt="An Overview of Challenges" width="400"/> \\
**An Overview of Challenges in Egocentric Text-Video Retrieval** \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
CVPR Workshop 2023, [Joint Ego4d/EPIC Workshop](https://sites.google.com/view/ego4d-epic-cvpr2023-workshop/) (Oral presentation) \\
[[Extended Abstract](https://arxiv.org/abs/2306.04345)] [[YouTube Ppt](https://youtu.be/XnUMScoOPvM)]

## PhD Research Topic 1: Semantic Text-to-Video Retrieval

(âœ… 3rd Place Award) **Exploiting Semantic Role Contextualized Video Features**\\
**for Multi-Instance Video Retrieval**  \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
CVPR Workshop 2022, Epic-Kitchens-100 MIR Challenge under [Joint Ego4d/EPIC Workshop](https://sites.google.com/view/cvpr2022w-ego4d-epic/)  \\
[[Technical Report](https://arxiv.org/abs/2206.14381)] [[(pseudo)Code](https://github.com/buraksatar/RoME_video_retrieval)]

<img src="https://buraksatar.github.io/images/cvpr'22_workshop.png" alt="Architecture" width="300"/>

**RoME: Role-aware Mixture-of-Expert Transformer for Text-to-Video Retrieval** \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
[[arXiv 2022 Preprint](https://arxiv.org/abs/2206.12845)] [[(pseudo)Code](https://github.com/buraksatar/RoME_video_retrieval)]

<img src="https://buraksatar.github.io/images/icip'21.png" alt="Overview of our model on text-to-video retrieval" width="400"/>

**Semantic Role Aware Correlation Transformer for Text to Video Retrieval** \\
**Burak Satar**, Zhu Hongyuan, Xavier Bresson, Joo-Hwee Lim \\
ICIP 2021 Full Paper (Oral presentation) and [ICCV Workshop 2021](https://sites.google.com/view/srvu-iccv21-workshop/papers?authuser=0) (Oral presentation)\\
[[arXiv](https://arxiv.org/abs/2206.12849)] [[(pseudo)Code](https://github.com/buraksatar/RoME_video_retrieval)] [[YouTube Ppt](https://www.youtube.com/watch?v=M7dHgv8fIkU)]

# Research during Master's Study

<img src="https://buraksatar.github.io/images/icann'18.png" alt="Detection and classification method" width="250"/> \\
Human Action Image Generation with Differential Privacy \\ 

Mingxuan Sun, **Qing Wang**, Zicheng Liu \\
2020 IEEE International Conference on Multimedia and Expo (ICME) \\
[[paper](https://par.nsf.gov/servlets/purl/10283631)] 



<span style="color:blue"> -------------------------------------------------------------------------------------------------- </span>

