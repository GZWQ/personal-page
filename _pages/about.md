---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a Research Scientist at Singapore Management University (SMU), working under the guidance of [Prof Chong-Wah Ngo](https://scholar.google.com/citations?user=HM39HrUAAAAJ&hl=en). My focus is on culturally aware multimodal Vision-Language Models (VLMs) with reasoning capabilities specific to Southeast Asia. <code style="color : LightSkyBlue">Reach out to me for collaboration on cultural context!</code>

I obtained my PhD from the College of Computing and Data Science (CCDS) at Nanyang Technological University (NTU) in Singapore, supported by the SINGA scholarship from the Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A\*STAR). My doctoral research focused on **Towards Semantic, Debiased and Moment Video Retrieval with Multi-modal Features** conducted under the supervision of [Prof. Joo Hwee Lim](https://scholar.google.com/citations?user=BjEDX4EAAAAJ&hl=en), [Dr Hongyuan Zhu](https://hongyuanzhu.github.io/) and [Prof. Hanwang Zhang](https://scholar.google.com.sg/citations?user=YG0DFyYAAAAJ&hl=en&inst=14102473421921925766). During my PhD studies, I had the opportunity to visit the University of Bristol, in the UK, collaborating with [Prof. Michael Wray](https://scholar.google.com/citations?user=gFQcKZMAAAAJ&hl=en&oi=ao&inst=14102473421921925766) in Dima Damen's research group. I completed my Masterâ€™s degree under the guidance of [Prof. Ahmet Emir Dirik](https://scholar.google.com/citations?user=cfgcBIEAAAAJ&hl=tr), specializing in vehicle detection. My professional experiences span a range of roles, including work at a start-up in Istanbul, Turkish Airlines Technology, and an internship at the University of Valencia. Additionally, I have provided advisory support to two award-winning start-ups located in London and Istanbul.

Recent News
======
* 10/2025: Another paper is submitted.
* 08/2025: A paper is accepted to EMNLP 2025!
* 03/2025: Started to work as a Research Scientist at SMU.

<span style="color:blue"> -------------------------------------------------------------------------------------------------- </span>

Publications
======
# Research during Post-Doctoral Work

<img src="https://seeingculture-benchmark.github.io/static/images/teaser.png" alt="Seeing Culture Benchmark" width="700"/>

**Seeing Culture: A Benchmark for Visual Reasoning and Grounding** \\
**Burak Satar\***, Zhixin Ma\*, Patrick Amadeus Irawan, Wilfried Ariel Mulyawan, Jing Jiang, Ee-Peng Lim, Chong-Wah Ngo \\
EMNLP 2025 Main Conference \\
[[Project Website](https://seeingculture-benchmark.github.io/)] [[Paper](https://aclanthology.org/2025.emnlp-main.1131)] [[arXiv](https://arxiv.org/abs/2509.16517)] [[Code](https://github.com/buraksatar/seeingculture)] [[ðŸ¤— Dataset](https://huggingface.co/datasets/Multimedia-SMU/seeingculture-benchmark)]

**Retrieval Augmented Reasoning Segmentation in Cultural Context** \\
Zhixin Ma\*, **Burak Satar\***, Patrick Amadeus Irawan, Wilfried Ariel Mulyawan, Phuong Anh Nguyen, Chong-Wah Ngo \\
Under peer review \\
[arXiv] (link to be updated)

# Research during Doctoral Study
## PhD Research Topic 3: Multimodal and Generative Video/Moment Retrieval

**Video Corpus Moment Retrieval in Long Ego-centric Videos with LLM and Audio Fusion** \\
**Burak Satar**, Joo Hwee Lim, Hanwang Zhang, M Furkan Ilaslan, Hongyuan Zhu, Michael Wray \\
(Under development)

**VG-TVP: Multimodal Procedural Planning via Visually Grounded Text-Video Prompting** \\
M Furkan Ilaslan, Ali Koksal, Kevin Qinghong Lin, **Burak Satar**, Mike Zheng Shou, Qianli Xu \\
AAAI 2025 Full Paper \\
[[arXiv](https://arxiv.org/abs/2412.11621)] [[Dataset Link](https://drive.google.com/drive/folders/1-Lka5F-Dh-Fz6CwHDJYjUqieXlt2GCR6)] [[Github](https://github.com/mfurkanilaslan/VG-TVP?tab=readme-ov-file)]

## PhD Research Topic 2: Debiased Text-to-Video Retrieval

<img src="https://buraksatar.github.io/images/scm_camready.png" alt="Structural Causal Model" width="400"/> \\
**Towards Debiasing Frame Length Bias in Text-Video Retrieval via Causal Intervention** \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
BMVC 2023 Full Paper, (Poster presentation) \\
[[arXiv](https://arxiv.org/abs/2309.09311)] [[YouTube Ppt](https://youtu.be/aMhNvTCkT8Y)] [[Poster](https://drive.google.com/file/d/10aXgkCl4PowFelEOyxJp4X90cTtub6Pt/view?usp=sharing)] [[Project Page](https://buraksatar.github.io/FrameLengthBias/)]

<img src="https://buraksatar.github.io/images/cvpr'23_workshop.png" alt="An Overview of Challenges" width="400"/> \\
**An Overview of Challenges in Egocentric Text-Video Retrieval** \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
CVPR Workshop 2023, [Joint Ego4d/EPIC Workshop](https://sites.google.com/view/ego4d-epic-cvpr2023-workshop/) (Oral presentation) \\
[[Extended Abstract](https://arxiv.org/abs/2306.04345)] [[YouTube Ppt](https://youtu.be/XnUMScoOPvM)]

## PhD Research Topic 1: Semantic Text-to-Video Retrieval

(âœ… 3rd Place Award) **Exploiting Semantic Role Contextualized Video Features**\\
**for Multi-Instance Video Retrieval**  \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
CVPR Workshop 2022, Epic-Kitchens-100 MIR Challenge under [Joint Ego4d/EPIC Workshop](https://sites.google.com/view/cvpr2022w-ego4d-epic/)  \\
[[Technical Report](https://arxiv.org/abs/2206.14381)] [[(pseudo)Code](https://github.com/buraksatar/RoME_video_retrieval)]

<img src="https://buraksatar.github.io/images/cvpr'22_workshop.png" alt="Architecture" width="300"/>

**RoME: Role-aware Mixture-of-Expert Transformer for Text-to-Video Retrieval** \\
**Burak Satar**, Zhu Hongyuan, Hanwang Zhang, Joo-Hwee Lim \\
[[arXiv 2022 Preprint](https://arxiv.org/abs/2206.12845)] [[(pseudo)Code](https://github.com/buraksatar/RoME_video_retrieval)]

<img src="https://buraksatar.github.io/images/icip'21.png" alt="Overview of our model on text-to-video retrieval" width="400"/>

**Semantic Role Aware Correlation Transformer for Text to Video Retrieval** \\
**Burak Satar**, Zhu Hongyuan, Xavier Bresson, Joo-Hwee Lim \\
ICIP 2021 Full Paper (Oral presentation) and [ICCV Workshop 2021](https://sites.google.com/view/srvu-iccv21-workshop/papers?authuser=0) (Oral presentation)\\
[[arXiv](https://arxiv.org/abs/2206.12849)] [[(pseudo)Code](https://github.com/buraksatar/RoME_video_retrieval)] [[YouTube Ppt](https://www.youtube.com/watch?v=M7dHgv8fIkU)]

# Research during Master's Study

<img src="https://buraksatar.github.io/images/icann'18.png" alt="Detection and classification method" width="250"/> \\
**Human Action Image Generation with Differential Privacy** \\

Mingxuan Sun, **Qing Wang**, Zicheng Liu \\
2020 IEEE International Conference on Multimedia and Expo (ICME) \\
[[paper](https://par.nsf.gov/servlets/purl/10283631)] 



<span style="color:blue"> -------------------------------------------------------------------------------------------------- </span>

